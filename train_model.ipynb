{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P19V1_20.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ax1</th>\n",
       "      <th>ay1</th>\n",
       "      <th>az1</th>\n",
       "      <th>gx1</th>\n",
       "      <th>gy1</th>\n",
       "      <th>gz1</th>\n",
       "      <th>ax2</th>\n",
       "      <th>ay2</th>\n",
       "      <th>az2</th>\n",
       "      <th>gx2</th>\n",
       "      <th>gy2</th>\n",
       "      <th>gz2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.434</td>\n",
       "      <td>-0.837</td>\n",
       "      <td>-1.717</td>\n",
       "      <td>1.022</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-1.031</td>\n",
       "      <td>-3.113</td>\n",
       "      <td>1.747</td>\n",
       "      <td>-1.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>-0.842</td>\n",
       "      <td>-1.846</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-1.027</td>\n",
       "      <td>-2.853</td>\n",
       "      <td>1.717</td>\n",
       "      <td>-1.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.434</td>\n",
       "      <td>-0.839</td>\n",
       "      <td>-1.717</td>\n",
       "      <td>1.289</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-1.028</td>\n",
       "      <td>-2.350</td>\n",
       "      <td>1.785</td>\n",
       "      <td>-1.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>-0.836</td>\n",
       "      <td>-1.724</td>\n",
       "      <td>1.106</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-1.026</td>\n",
       "      <td>-2.396</td>\n",
       "      <td>1.831</td>\n",
       "      <td>-1.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>-1.671</td>\n",
       "      <td>1.022</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-1.023</td>\n",
       "      <td>-2.335</td>\n",
       "      <td>1.923</td>\n",
       "      <td>-1.404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ax1    ay1    az1    gx1    gy1    gz1    ax2    ay2    az2    gx2  \\\n",
       "0  0.042 -0.434 -0.837 -1.717  1.022  0.816  0.133  0.005 -1.031 -3.113   \n",
       "1  0.043 -0.437 -0.842 -1.846  0.916  0.496  0.135  0.005 -1.027 -2.853   \n",
       "2  0.044 -0.434 -0.839 -1.717  1.289  0.687  0.133  0.004 -1.028 -2.350   \n",
       "3  0.040 -0.438 -0.836 -1.724  1.106  0.732  0.135  0.005 -1.026 -2.396   \n",
       "4  0.044 -0.438 -0.838 -1.671  1.022  0.534  0.135  0.003 -1.023 -2.335   \n",
       "\n",
       "     gy2    gz2  \n",
       "0  1.747 -1.862  \n",
       "1  1.717 -1.869  \n",
       "2  1.785 -1.801  \n",
       "3  1.831 -1.640  \n",
       "4  1.923 -1.404  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import torch    #if error, restart kernel\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "Fs = 100  # Sampling frequency\n",
    "\n",
    "# Path to the folder containing the CSV files\n",
    "folder_path = \"TFO Data\\IMU\"\n",
    "\n",
    "# Get the list of CSV files in the folder\n",
    "file_list = glob.glob(folder_path + \"\\*.csv\")\n",
    "file_path = file_list[0]\n",
    "\n",
    "# Read the CSV file into a pandas dataframe\n",
    "df = pd.read_csv(file_path)\n",
    "df = df[df.columns[2:-1]]  # Remove the time, index, and temperature columns\n",
    "    \n",
    "# Show the head of the dataframe\n",
    "title = file_path.split(\"\\\\\")[-1]\n",
    "print(title)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Normalize the data\n",
    "# scaler = StandardScaler()\n",
    "# df = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110172,)\n"
     ]
    }
   ],
   "source": [
    "x = df['ax1']\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (110073, 100)\n"
     ]
    }
   ],
   "source": [
    "from Utils.models import VAE\n",
    "from Utils.dataloader import DataLoaderGenerator\n",
    "from Utils.processing import window_data\n",
    "\n",
    "# Window the data\n",
    "data = window_data(x, 100)\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "# Create a DataLoader object\n",
    "dataloader = DataLoaderGenerator(data, batch_size=32)\n",
    "train_loader, val_loader = dataloader.generate()\n",
    "\n",
    "# Initialize the model\n",
    "vae = VAE(input_dims=100, latent_dims=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0060, 0.0050, 0.0100, 0.0110, 0.0110, 0.0140, 0.0090, 0.0180, 0.0150,\n",
      "        0.0150, 0.0190, 0.0170, 0.0160, 0.0140, 0.0190, 0.0230, 0.0180, 0.0210,\n",
      "        0.0200, 0.0240, 0.0150, 0.0120, 0.0080, 0.0070, 0.0100, 0.0070, 0.0060,\n",
      "        0.0080, 0.0080, 0.0090, 0.0130, 0.0080, 0.0130, 0.0160, 0.0180, 0.0160,\n",
      "        0.0140, 0.0200, 0.0180, 0.0200, 0.0180, 0.0190, 0.0190, 0.0140, 0.0150,\n",
      "        0.0160, 0.0160, 0.0150, 0.0200, 0.0190, 0.0160, 0.0150, 0.0170, 0.0180,\n",
      "        0.0180, 0.0120, 0.0080, 0.0050, 0.0050, 0.0100, 0.0040, 0.0060, 0.0150,\n",
      "        0.0220, 0.0230, 0.0260, 0.0220, 0.0260, 0.0250, 0.0220, 0.0210, 0.0170,\n",
      "        0.0170, 0.0170, 0.0200, 0.0250, 0.0240, 0.0250, 0.0230, 0.0240, 0.0210,\n",
      "        0.0180, 0.0130, 0.0100, 0.0000, 0.0030, 0.0010, 0.0000, 0.0050, 0.0070,\n",
      "        0.0070, 0.0180, 0.0170, 0.0220, 0.0190, 0.0250, 0.0270, 0.0270, 0.0270,\n",
      "        0.0230])\n"
     ]
    }
   ],
   "source": [
    "print(train_loader.dataset.tensors[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_loader: 99065\n",
      "Length of val_loader: 11008\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of train_loader: {len(train_loader.dataset)}\")\n",
    "print(f\"Length of val_loader: {len(val_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "def hello(a,b,c):\n",
    "    print(a,b,c)\n",
    "    return a+b+c\n",
    "\n",
    "abs = [1,2,3]\n",
    "print(hello(*abs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), padding=(31,))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(21,))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(11,))\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Conv1d(128, 512, kernel_size=(4,), stride=(2,), padding=(5,))\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): Linear(in_features=12288, out_features=24, bias=True)\n",
      "    (10): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (code_mean): Linear(in_features=24, out_features=6, bias=True)\n",
      "  (code_std_dev): Linear(in_features=24, out_features=6, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=24, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=24, out_features=12288, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Unflatten(dim=1, unflattened_size=(512, 24))\n",
      "    (5): ConvTranspose1d(512, 128, kernel_size=(4,), stride=(2,), padding=(5,))\n",
      "    (6): LeakyReLU(negative_slope=0.01)\n",
      "    (7): ConvTranspose1d(128, 64, kernel_size=(3,), stride=(2,), padding=(11,), output_padding=(1,))\n",
      "    (8): LeakyReLU(negative_slope=0.01)\n",
      "    (9): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), padding=(21,), output_padding=(1,))\n",
      "    (10): LeakyReLU(negative_slope=0.01)\n",
      "    (11): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), padding=(31,), output_padding=(1,))\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 32, 80]             128\n",
      "         LeakyReLU-2               [-1, 32, 80]               0\n",
      "            Conv1d-3               [-1, 64, 60]           6,208\n",
      "         LeakyReLU-4               [-1, 64, 60]               0\n",
      "            Conv1d-5              [-1, 128, 40]          24,704\n",
      "         LeakyReLU-6              [-1, 128, 40]               0\n",
      "            Conv1d-7              [-1, 512, 24]         262,656\n",
      "         LeakyReLU-8              [-1, 512, 24]               0\n",
      "           Flatten-9                [-1, 12288]               0\n",
      "           Linear-10                   [-1, 24]         294,936\n",
      "        LeakyReLU-11                   [-1, 24]               0\n",
      "           Linear-12                    [-1, 6]             150\n",
      "           Linear-13                    [-1, 6]             150\n",
      "           Linear-14                   [-1, 24]             168\n",
      "        LeakyReLU-15                   [-1, 24]               0\n",
      "           Linear-16                [-1, 12288]         307,200\n",
      "        LeakyReLU-17                [-1, 12288]               0\n",
      "        Unflatten-18              [-1, 512, 24]               0\n",
      "  ConvTranspose1d-19              [-1, 128, 40]         262,272\n",
      "        LeakyReLU-20              [-1, 128, 40]               0\n",
      "  ConvTranspose1d-21               [-1, 64, 60]          24,640\n",
      "        LeakyReLU-22               [-1, 64, 60]               0\n",
      "  ConvTranspose1d-23               [-1, 32, 80]           6,176\n",
      "        LeakyReLU-24               [-1, 32, 80]               0\n",
      "  ConvTranspose1d-25               [-1, 1, 100]              97\n",
      "================================================================\n",
      "Total params: 1,189,485\n",
      "Trainable params: 1,189,485\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.92\n",
      "Params size (MB): 4.54\n",
      "Estimated Total Size (MB): 5.45\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "vae = vae.to('cuda')\n",
    "print(vae)\n",
    "summary(vae, (1, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 342.9369812011719\n",
      "Epoch 2/10, Loss: 342.9376220703125\n",
      "Epoch 3/10, Loss: 342.9325256347656\n",
      "Epoch 4/10, Loss: 342.9334716796875\n",
      "Epoch 5/10, Loss: 342.9325866699219\n",
      "Epoch 6/10, Loss: 342.9323425292969\n",
      "Epoch 7/10, Loss: 342.9314270019531\n",
      "Epoch 8/10, Loss: 342.9344482421875\n",
      "Epoch 9/10, Loss: 342.9320068359375\n",
      "Epoch 10/10, Loss: 342.929931640625\n"
     ]
    }
   ],
   "source": [
    "vae.train_model(train_loader, n_epochs=10)  # Loss function might be wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save_model(\"Weights/vae.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.load_model(\"Weights/vae.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LSTM data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_training_data = vae.encode_data(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99040, 6)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader object\n",
    "lstm_dataloader = DataLoaderGenerator(encoded_training_data, batch_size=32)\n",
    "train_loader_lstm, val_loader_lstm = lstm_dataloader.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([89136, 1, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader_lstm.dataset.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RNNBase.__init__() got an unexpected keyword argument 'return_sequences'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mUtils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM\n\u001b[1;32m----> 3\u001b[0m lstm \u001b[38;5;241m=\u001b[39m \u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m lstm \u001b[38;5;241m=\u001b[39m lstm\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(lstm)\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive - University of California, Davis\\Documents\\Davis\\2024 xSpring\\EEC 289A\\Unsupervised-Anomaly-Detection\\Utils\\models.py:188\u001b[0m, in \u001b[0;36mLSTM.__init__\u001b[1;34m(self, latent_dims, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28msuper\u001b[39m(LSTM, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dims \u001b[38;5;241m=\u001b[39m latent_dims\n\u001b[1;32m--> 188\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_dims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m optimizer\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive - University of California, Davis\\Documents\\Davis\\2024 xSpring\\EEC 289A\\Unsupervised-Anomaly-Detection\\Utils\\models.py:207\u001b[0m, in \u001b[0;36mLSTM.build_model\u001b[1;34m(self, n_neurons, code_size)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_neurons: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m, code_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m):\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m--> 207\u001b[0m         \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neurons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[0;32m    208\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLSTM(n_neurons, n_neurons, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m    209\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLSTM(n_neurons, code_size, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m    210\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLinear(code_size, code_size) \u001b[38;5;66;03m# Add a linear layer to remove affect of previous layers activation function\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py:770\u001b[0m, in \u001b[0;36mLSTM.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 770\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLSTM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: RNNBase.__init__() got an unexpected keyword argument 'return_sequences'"
     ]
    }
   ],
   "source": [
    "from Utils.models import LSTM\n",
    "\n",
    "lstm = LSTM()\n",
    "lstm = lstm.to('cuda')\n",
    "print(lstm)\n",
    "summary(lstm, (1, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.train_model(train_loader_lstm, n_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
